{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment 3**\n",
    "\n",
    "**CNN MODEL FOR FLOWER CLASSIFICATION**\n",
    "\n",
    "**Trained by Team ID : PNT2022TMID43250**\n",
    "\n",
    "**Pre-Requisites**\n",
    "\n",
    "from google.colab import drive  \n",
    "drive.mount('/content/drive')\n",
    "\n",
    "Drive already mounted at /content/drive; to attempt to forcibly remount,\n",
    "call drive.mount(\"/content/drive\", force_remount=True).\n",
    "\n",
    "**STEP 1 UNZIP FILES**\n",
    "\n",
    "cd/content/drive/MyDrive/AI_IBM\n",
    "\n",
    "/content/drive/MyDrive/AI_IBM\n",
    "\n",
    "!unzip Flowers-Dataset.zip\n",
    "\n",
    "Archive: Flowers-Dataset.zip  \n",
    "replace flowers/daisy/100080576_f52e8ee070_n.jpg? \\[y\\]es, \\[n\\]o,\n",
    "\\[A\\]ll, \\[N\\]one, \\[r\\]ename: N\n",
    "\n",
    "**STEP 2 Image Augumentation**\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,\n",
    "zoom_range=0.2,horizontal_flip=True,vertical_flip=False)\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "x_train=train_datagen.flow_from_directory(r\"/content/drive/MyDrive/AI_IBM/flowers\",target_size=(64,64),class_mode='categorical',batch_size=24)\n",
    "\n",
    "Found 4317 images belonging to 5 classes.\n",
    "\n",
    "x_test=test_datagen.flow_from_directory(r\"/content/drive/MyDrive/AI_IBM/flowers\",target_size=(64,64),class_mode='categorical',batch_size=24)\n",
    "\n",
    "Found 4317 images belonging to 5 classes.\n",
    "\n",
    "x_train.class_indices\n",
    "\n",
    "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}\n",
    "\n",
    "**Step -3 Initializing CNN And Create Model**\n",
    "\n",
    "from tensorflow.keras.models import Sequential  \n",
    "from tensorflow.keras.layers import\n",
    "Dense,Convolution2D,MaxPooling2D,Flatten\n",
    "\n",
    "**Step -4 Add layers**\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "**4.1 Input Layers (Convolution ,MaxPooling,Flatten)**\n",
    "\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.summary()\n",
    "\n",
    "Model: \"sequential\"  \n",
    "\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_  \n",
    "Layer (type) Output Shape Param \\#  \n",
    "=================================================================  \n",
    "conv2d (Conv2D) (None, 62, 62, 32) 896  \n",
    "  \n",
    "max_pooling2d (MaxPooling2D (None, 31, 31, 32) 0  \n",
    ")  \n",
    "  \n",
    "flatten (Flatten) (None, 30752) 0  \n",
    "  \n",
    "=================================================================  \n",
    "Total params: 896  \n",
    "Trainable params: 896  \n",
    "Non-trainable params: 0  \n",
    "\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n",
    "\n",
    "**4.2 Hidden Layers**\n",
    "\n",
    "model.add(Dense(300,activation='relu'))  \n",
    "model.add(Dense(150,activation='relu'))\n",
    "\n",
    "**4.3 Output Layers**\n",
    "\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=\\['accuracy'\\])\n",
    "\n",
    "len(x_train)\n",
    "\n",
    "180\n",
    "\n",
    "**Step -5 Train the Model**\n",
    "\n",
    "model.fit_generator(x_train,steps_per_epoch=len(x_train),\n",
    "validation_data=x_test, validation_steps=len(x_test), epochs= 30)\n",
    "\n",
    "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1:\n",
    "UserWarning: \\`Model.fit_generator\\` is deprecated and will be removed\n",
    "in a future version. Please use \\`Model.fit\\`, which supports\n",
    "generators.  \n",
    "\"\"\"Entry point for launching an IPython kernel.\n",
    "\n",
    "Epoch 1/30  \n",
    "180/180 \\[==============================\\] - 393s 2s/step - loss: 1.3213\n",
    "- accuracy: 0.4714 - val_loss: 1.1275 - val_accuracy: 0.5532  \n",
    "Epoch 2/30  \n",
    "180/180 \\[==============================\\] - 74s 409ms/step - loss:\n",
    "1.0600 - accuracy: 0.5854 - val_loss: 0.9406 - val_accuracy: 0.6301  \n",
    "Epoch 3/30  \n",
    "180/180 \\[==============================\\] - 73s 405ms/step - loss:\n",
    "0.9678 - accuracy: 0.6247 - val_loss: 0.9603 - val_accuracy: 0.6203  \n",
    "Epoch 4/30  \n",
    "180/180 \\[==============================\\] - 77s 429ms/step - loss:\n",
    "0.8884 - accuracy: 0.6546 - val_loss: 0.8187 - val_accuracy: 0.6938  \n",
    "Epoch 5/30  \n",
    "180/180 \\[==============================\\] - 76s 422ms/step - loss:\n",
    "0.8358 - accuracy: 0.6787 - val_loss: 0.7393 - val_accuracy: 0.7225  \n",
    "Epoch 6/30  \n",
    "180/180 \\[==============================\\] - 75s 418ms/step - loss:\n",
    "0.7924 - accuracy: 0.6965 - val_loss: 0.8389 - val_accuracy: 0.6928  \n",
    "Epoch 7/30  \n",
    "180/180 \\[==============================\\] - 73s 405ms/step - loss:\n",
    "0.7521 - accuracy: 0.7158 - val_loss: 0.8503 - val_accuracy: 0.6789  \n",
    "Epoch 8/30  \n",
    "180/180 \\[==============================\\] - 74s 411ms/step - loss:\n",
    "0.7048 - accuracy: 0.7313 - val_loss: 0.6492 - val_accuracy: 0.7521  \n",
    "Epoch 9/30  \n",
    "180/180 \\[==============================\\] - 72s 400ms/step - loss:\n",
    "0.6502 - accuracy: 0.7521 - val_loss: 0.6458 - val_accuracy: 0.7438  \n",
    "Epoch 10/30  \n",
    "180/180 \\[==============================\\] - 74s 409ms/step - loss:\n",
    "0.6182 - accuracy: 0.7684 - val_loss: 0.5721 - val_accuracy: 0.7818  \n",
    "Epoch 11/30  \n",
    "180/180 \\[==============================\\] - 72s 402ms/step - loss:\n",
    "0.5662 - accuracy: 0.7931 - val_loss: 0.5968 - val_accuracy: 0.7725  \n",
    "Epoch 12/30  \n",
    "180/180 \\[==============================\\] - 72s 401ms/step - loss:\n",
    "0.5600 - accuracy: 0.7908 - val_loss: 0.6907 - val_accuracy: 0.7612  \n",
    "Epoch 13/30  \n",
    "180/180 \\[==============================\\] - 72s 399ms/step - loss:\n",
    "0.5064 - accuracy: 0.8138 - val_loss: 0.5185 - val_accuracy: 0.8117  \n",
    "Epoch 14/30  \n",
    "180/180 \\[==============================\\] - 71s 394ms/step - loss:\n",
    "0.4830 - accuracy: 0.8249 - val_loss: 0.3613 - val_accuracy: 0.8673  \n",
    "Epoch 15/30  \n",
    "180/180 \\[==============================\\] - 71s 397ms/step - loss:\n",
    "0.4650 - accuracy: 0.8196 - val_loss: 0.3396 - val_accuracy: 0.8768  \n",
    "Epoch 16/30  \n",
    "180/180 \\[==============================\\] - 71s 393ms/step - loss:\n",
    "0.4117 - accuracy: 0.8559 - val_loss: 0.3472 - val_accuracy: 0.8738  \n",
    "Epoch 17/30  \n",
    "180/180 \\[==============================\\] - 71s 397ms/step - loss:\n",
    "0.3892 - accuracy: 0.8631 - val_loss: 0.3314 - val_accuracy: 0.8826  \n",
    "Epoch 18/30  \n",
    "180/180 \\[==============================\\] - 70s 389ms/step - loss:\n",
    "0.3441 - accuracy: 0.8726 - val_loss: 0.4008 - val_accuracy: 0.8589  \n",
    "Epoch 19/30  \n",
    "180/180 \\[==============================\\] - 73s 404ms/step - loss:\n",
    "0.3467 - accuracy: 0.8719 - val_loss: 0.2484 - val_accuracy: 0.9060  \n",
    "Epoch 20/30  \n",
    "180/180 \\[==============================\\] - 72s 398ms/step - loss:\n",
    "0.3327 - accuracy: 0.8758 - val_loss: 0.2234 - val_accuracy: 0.9210  \n",
    "Epoch 21/30  \n",
    "180/180 \\[==============================\\] - 73s 403ms/step - loss:\n",
    "0.2807 - accuracy: 0.9009 - val_loss: 0.2830 - val_accuracy: 0.9036  \n",
    "Epoch 22/30  \n",
    "180/180 \\[==============================\\] - 70s 392ms/step - loss:\n",
    "0.2751 - accuracy: 0.9013 - val_loss: 0.2392 - val_accuracy: 0.9141  \n",
    "Epoch 23/30  \n",
    "180/180 \\[==============================\\] - 73s 404ms/step - loss:\n",
    "0.2549 - accuracy: 0.9097 - val_loss: 0.2221 - val_accuracy: 0.9189  \n",
    "Epoch 24/30  \n",
    "180/180 \\[==============================\\] - 72s 399ms/step - loss:\n",
    "0.2412 - accuracy: 0.9243 - val_loss: 0.2029 - val_accuracy: 0.9291  \n",
    "Epoch 25/30  \n",
    "180/180 \\[==============================\\] - 72s 402ms/step - loss:\n",
    "0.2360 - accuracy: 0.9199 - val_loss: 0.1965 - val_accuracy: 0.9307  \n",
    "Epoch 26/30  \n",
    "180/180 \\[==============================\\] - 72s 401ms/step - loss:\n",
    "0.2199 - accuracy: 0.9201 - val_loss: 0.1919 - val_accuracy: 0.9331  \n",
    "Epoch 27/30  \n",
    "180/180 \\[==============================\\] - 72s 400ms/step - loss:\n",
    "0.2008 - accuracy: 0.9363 - val_loss: 0.1218 - val_accuracy: 0.9560  \n",
    "Epoch 28/30  \n",
    "180/180 \\[==============================\\] - 73s 406ms/step - loss:\n",
    "0.1889 - accuracy: 0.9310 - val_loss: 0.2838 - val_accuracy: 0.9108  \n",
    "Epoch 29/30  \n",
    "180/180 \\[==============================\\] - 70s 389ms/step - loss:\n",
    "0.2046 - accuracy: 0.9275 - val_loss: 0.2116 - val_accuracy: 0.9307  \n",
    "Epoch 30/30  \n",
    "180/180 \\[==============================\\] - 70s 392ms/step - loss:\n",
    "0.1886 - accuracy: 0.9372 - val_loss: 0.2091 - val_accuracy: 0.9280\n",
    "\n",
    "\\<keras.callbacks.History at 0x7f3e15438e50\\>\n",
    "\n",
    "**Step -6 Save The model**\n",
    "\n",
    "model.save('Flowers_classification_model1.h5')\n",
    "\n",
    "**Step -7 Test The model**\n",
    "\n",
    "ls\n",
    "\n",
    "flowers/ Flowers_classification_model1.h5 Flowers-Dataset.zip video.mp4\n",
    "\n",
    "import numpy as np  \n",
    "from tensorflow.keras.models import load_model  \n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "*\\# Load the model*  \n",
    "model=load_model('Flowers_classification_model1.h5')\n",
    "\n",
    "img=image.load_img(r\"/content/s3.jpg\",target_size=(64,64))  \n",
    "x=image.img_to_array(img)  \n",
    "x=np.expand_dims(x,axis=0)  \n",
    "y=np.argmax(model.predict(x),axis=1)  \n",
    "*\\# x_train.class_indices*  \n",
    "index=\\['daisy','dandelion','rose','sunflower','tulip'\\]  \n",
    "index\\[y\\[0\\]\\]\n",
    "\n",
    "{\"type\":\"string\"}\n",
    "\n",
    "**We Achieved 93 percent of accuracy with this model**\n",
    "\n",
    "**Trained by Team ID : PNT2022TMID43250**"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
